#Find the most interconnected wikipedia pages
###Author: Mazin Jindeel
###Date: 5/15

#Instructions:

Note: These steps may take a while, as the data is quite large. 

1. Download dataset
    * download the wikipedia dataset in XML
      [here](http://en.wikipedia.org/wiki/Wikipedia:Database_download#English-language_Wikipedia). 
    * Note: you will need at about 12GB free on your disk to complete this step. 

2. Uncompress the data. 
	* `bunzip2 enwiki-20170820-pages-articles.xml.bz2`

3. run parseScript.sh to extract just titles and links.
    * `./ parseScript.sh enwiki-20180820-pages-articles.xml graph_input.txt`
    * output should shrink to ~10GB, so have at least that much space free. 
	* Links to namespaces are removed, because they are not considered pages
