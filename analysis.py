#!usr/bin/python3

#Usage: ./analysis.py WIKIPARSED MOST_IN MOST_OUT
# WIKIPARSED is the parsed wikipedia file generated by the parse script
# MOST_IN will rank each page in order of most incoming links
# MOST_OUT will rank each page in order of most outgoing links

import networkx as nx
import sys

g = nx.DiGraph()

if len(sys.argv) < 4: 
  print("Usage: ./grapher.py WIKIPARSED MOST_IN MOST_OUT")
  exit(1)

#open file
input_file = open(sys.argv[1], 'r')

current_node = ""
while True:
  line = input_file.readline().strip()
  #if it starts with <title>, it's a title
  if not line: break
  #if it starts with brackets, it's a link from <currentpage>
  if line[0] == "[":
    line = line[2:-2] #[[ = 2, ]] = 2
    g.add_edge(line, current_node)
  elif line[0] == "<":
    line = line[7:-8] # <title> = 7, </title> = 8
    current_node = line


most_out_links = {node:len(g.out_edges(node)) for node in g.nodes()}
out_sorted = sorted(most_out_links.items(), key=lambda kv: kv[1], reverse=True)
out_file = open(sys.argv[2], 'w')
for x in out_sorted:
  out_file.write(str(x) + "\n")
out_file.close()

most_in_links = {node:len(g.in_edges(node)) for node in g.nodes()}
in_sorted = sorted(most_in_links.items(), key=lambda kv: kv[1], reverse=True)
in_file = open(sys.argv[3], 'w')
for x in in_sorted:
  in_file.write(str(x) + "\n")
in_file.close()




